\section{Related Works}
The field of cybersecurity is a dynamic, constantly evolving realm with a reaction based 
approach as defensive mechanism must be applied to continuously evolving threats and vice versa. 
In approaching such an environment a solution to both issues must be adaptive. Machine 
Learning (ML), a subfield of Artificial Intelligence (AI), offers the ability to draw connections and create predictions based on provided input data. More specifically, Deep Learning (DL), a subset of ML utilizes a "cascade of multiple layers of nonlinear processing units for feature extraction and transformation". %\cite{ml_overview}
In focusing this application two fields have been identified for having both sufficient data for 
model development and validation of performance accuracy and validity: malware classification 
and network intrusion detection. 

Intrusion detection "aims to discover illicit activities 
within a computer or a network" with a focus on anomaly detection, threat detection, and ML 
based classification. %cite{ml_general}
Many traditional Entrusting Detection Systems (IDS) are limited in their ability to respond solely to know threats and not efficiently recognize and respond to dynamic network environments. ML approaches offer promise and lend to increase overall detection capabilities while providing greater accuracy in detecting threats not expressly identified. An important factor in applying ML and DL models to intrusion detection is the dataset used for training a testing. It must be diverse and include a balance of "normal" and "anomalous" behavior in order to reduce the risk of over fitting and effectively identify "unseen" threats. %cite{nids1}
There exist various evaluation methods and metric applications for measuring model accuracy and efficiency notably precision (ratio of correctly predicted attacks to all samples predicted as attacks), f-measure (the harmonic means of precision and detection rate of the system), and true negative rate (the ratio of the number of correctly classified 'normal' samples to all samples that are 'normal') %cite{nids2}
60 percent of proposed methodologies utilized the KDD Cup'99 dataset with growing recommendation leaning towards model implementation on the most recent publicly available dataset, CSE-CIC-IDS2018.

When viewing existing research in terms of model development, "The most common ML (also called Shallow Learning) algorithms used for IDS are Decision Tree, K-Nearest Neighbor (KNN), Artificial Neural Network (ANN), Support Vector Machine (SVM), K-Mean Clustering, Fast Learning Network, and Ensemble Methods." \cite{nids1} These models perform at varying degress of accuracy with important evaluation criteria pertaining to the systemâ€™s capabilities: What can it detect, and why? What can it not detect, and why not? How reliably does it operate? Where does it break?"\cite{nids1} Existing challenges relevant to such development includes,  "The domain-specific challenges include: (i) the need for outlier detection, while machine learning instead performs better at finding similarities; (ii) very high costs of classification errors, which render error rates as encountered in other domains unrealistic; (iii) a semantic gap between detection results and their operational interpretation; (iv) the enormous variability of benign traffic, making it difficult to find stable notions of normality; (v) significant challenges with performing sound evaluation; and (vi) the need to operate in an adversarial setting" \cite{nids1}

The second area of focus exists in malware classification utilizing ML models. Malware attacks can be identified and categorized in various elements such as spear phishing, hijacking, DDOS, RAT, etc. Approaches can be applied to predicting the probability of endpoint penetrating or the prediction of manipulation on various endpoint nodes. Similar to the Network Intrusion Detection approaches, malware classification requires a balanced and diverse set of training and validation data. The majority of applications rely on signature-based data for training and model processing yet the potential for behavior based detection has been explored. 

When exploring the usage of ML models it is important to consider risk factors associated with their usage both in development and once employed as defensive mechanisms. Poisoning of AI models is of growing concern and an attack vector that can be mitigated against. The ultimate goal of model poisoning is to misclasify results often through means of adversarial crafted inputs to the model. Defenses are divided into model based and data based considerations. It is essential to ensure a secure environment when training and executing the model while properly securing each node against manipulation.

As a point of further research the area of malware classification is also going to be explored. This analysis will primarily rely on the Elastic Malware Benchmark for Empowering Researchers (EMBER) data set with 3 total iterations the most recent of which being released in 2018. Existing models demonstrate a 98 percent detection rate and a 93 percent detection rate. TODO: complete this section once EMBER research is complete